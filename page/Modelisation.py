import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, 
    f1_score, roc_auc_score, confusion_matrix, classification_report
)
from xgboost import XGBClassifier


# ============================================================
#  ğŸ”· TITRE PRINCIPAL
# ============================================================
st.title("ğŸ¤– ModÃ©lisation & Ã‰valuation")


# ============================================================
#  ğŸ”· IMPORTATION & PRÃ‰PARATION DES DONNÃ‰ES
# ============================================================

data = pd.read_csv("Financial_inclusion_dataset.csv")
df = data.copy()


# --- Nettoyage ---
df = df.drop('uniqueid', axis=1)

# Encodage
label_encoder = LabelEncoder()
for col in df.select_dtypes(exclude='number').columns:
    df[col] = label_encoder.fit_transform(df[col])

st.success("Variables catÃ©gorielles encodÃ©es et colonne inutile supprimÃ©e !")


# ============================================================
#  ğŸ”· ANALYSE DE LA CORRÃ‰LATION
# ============================================================
st.header("ğŸ” Analyse de la CorrÃ©lation ")

correlation = df.corr()

st.subheader("ğŸ”¥ Heatmap des CorrÃ©lations")
fig, ax = plt.subplots(figsize=(6, 4))
sns.heatmap(correlation, annot=False, cmap='coolwarm', ax=ax)
st.pyplot(fig)


st.subheader("ğŸ¯ CorrÃ©lation avec la variable cible : `bank_account`")
correlation_target = correlation["bank_account"].sort_values()

fig2, ax2 = plt.subplots(figsize=(3, 4))
sns.heatmap(correlation.loc[correlation_target.index, ["bank_account"]], annot=True, cmap='coolwarm', ax=ax2)
st.pyplot(fig2)


# --- Fonction pour sÃ©lectionner les colonnes corrÃ©lÃ©es ---
def get_correlated_columns(corr_df, target='bank_account', threshold=0.1, absolute=True):
    s = corr_df[target]
    if absolute:
        s = s.abs()
    s = s.drop(labels=[target], errors='ignore')
    return s[s >= threshold].sort_values(ascending=False)

seuil = 0.05
cols_correl = get_correlated_columns(correlation, threshold=seuil)
liste_cols = list(cols_correl.index)

st.write("### ğŸ§© Variables sÃ©lectionnÃ©es :")
st.table(liste_cols)


# ============================================================
#  ğŸ”· SÃ‰PARATION DES DONNÃ‰ES
# ============================================================
st.header("ğŸ§ª SÃ©lection & PrÃ©paration des DonnÃ©es")

features = liste_cols
target = "bank_account"

X = df[features]
y = df[target]

st.write("Variables explicatives :", features)
st.write("Variable cible :", target)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

st.info("DÃ©coupage effectuÃ© : 80% train / 20% test avec stratification.")


# ============================================================
#  ğŸ”· SCALING
# ============================================================
st.subheader("âš™ï¸ Mise Ã  l'Ã‰chelle (StandardScaler)")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

st.success("DonnÃ©es mises Ã  l'Ã©chelle avec succÃ¨s !")


# ============================================================
#  ğŸ”· MODÃ‰LISATION (XGBoost)
# ============================================================
st.header("ğŸ¤– EntraÃ®nement du ModÃ¨le XGBoost")

model = XGBClassifier(
    eval_metric='logloss',
    n_estimators=100,
    max_depth=6,
    n_jobs=-1,
    random_state=42
)

model.fit(X_train_scaled, y_train)
st.success("ModÃ¨le entraÃ®nÃ© avec succÃ¨s ! ğŸ¯")


# ============================================================
#  ğŸ”· Ã‰VALUATION DU MODÃˆLE
# ============================================================
y_pred = model.predict(X_test_scaled)
y_probs = model.predict_proba(X_test_scaled)[:, 1]

st.header("ğŸ“Š Ã‰valuation du ModÃ¨le")

acc  = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec  = recall_score(y_test, y_pred)
f1   = f1_score(y_test, y_pred)
auc  = roc_auc_score(y_test, y_probs)

st.markdown(f"#### ğŸ”¹ Accuracy : **{acc:.4f}**")
st.markdown(f"#### ğŸ”¹ Precision : **{prec:.4f}**")
st.markdown(f"#### ğŸ”¹ Recall : **{rec:.4f}**")
st.markdown(f"#### ğŸ”¹ F1-score : **{f1:.4f}**")
st.markdown(f"#### ğŸ”¹ AUC-ROC : **{auc:.4f}**")


# --- Matrice de confusion ---
st.subheader("ğŸ“˜ Matrice de Confusion")
fig_cm, ax_cm = plt.subplots()
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', ax=ax_cm)
st.pyplot(fig_cm)


# --- Rapport de classification ---
st.subheader("ğŸ“„ Rapport de Classification")
st.text(classification_report(y_test, y_pred))
